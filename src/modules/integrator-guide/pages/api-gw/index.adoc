include::ROOT:partial$variables.adoc[]

= API Gateway

The API gateway facility allows you to define custom endpoints that can support custom authentication methods, request validation, and rate limiting.

These endpoints can be used to define custom endpoint for incoming webhooks, to process data provided by some external integration, or to proxy requests to another service.

Most of the basic operations can be achieved with the built-in functionality; more advanced operations can be implemented with simple JavaScript code snippets or xref:automation/workflows/index.adoc[workflows].

== Defining a new endpoint

To define a new endpoint, navigate to your {PRODUCT_NAME} instance (for example http://latest.cortezaproject.org/) and click ok tne "admin area" application.

.The screenshot shows the app selector and the admin area application.
image::apigw/app-selector.png[role="data-zoomable"]

In the admin are, navigate to the menu:System[API Gateway] sub-page.
From the admin area you can create and update your endpoints endpoints, as well as manage their access control.

.The screenshot shows the route list screen.
image::apigw/route-list.png[role="data-zoomable"]

When you click on the btn:[new] button, a new screen will appear where you need to provide the base parameters of your endpoint.

.The screenshot shows the user interface for creating a new endpoint.
image::apigw/route-create.png[role="data-zoomable"]

* *endpoint* defines the path for the endpoint,
* *method* defines what HTTP method the endpoint will listen for.

The endpoint will be accessible under `$BASE_URL/api/$YOUR_ENDPOINT`.
To examplify; the `/test-api` endpoint for the `https://latest.cortezaproject.org` instance is available under `https://latest.cortezaproject.org/api/test-api`

[NOTE]
====
*DevNote* can I have multiple endpoints with same routes but different methods?
====

When you submit the forum, an additional "filter list" section opens below the base parameters.
These filters allow you to validate and process requests; as well as defining the response.

Later sections go more in depth regarding specific filters, what they do, and how they should be used.

.The screenshot shows the user interface for attaching filters to the endpoint.
image::apigw/route-filters.png[role="data-zoomable"]

// workflow connections 
== Workflow Connections 

Corteza Workflows allow you to implement custom business logic without the need for any programming knowledge. If you wish to learn more about a specific topic, refer to the . xref:workflow-guide:https://docs.cortezaproject.org/corteza-docs/2021.3/integrator-guide/workflows/index.html[Corteza workflow Guide]

In contrast to Automation scripts, workflows are presented as a simplified BPMN diagram, allowing you to configure instead of code. You are not required to have any BPMN knowledge, although it might be helpful.

In order to extend the Gateway functionality as well as bring greater front end reach it was decided to integrate Corteza Workflows. This gives user very high level of manipulation and automation using already well developed and tested feature. 

.Block image
image::apigw/workflow-example.png[role="data-zoomable"]


=== How to

In order for a user to connect a newly created API route an already existing workflow must be created and chosen. 

* From the admin panel on the left hand side select Horizon(API Gateway).
* Select the route you would like to edit or simply create a new one.
* On the routes page under the filer lists on the bottom half of the page, select the "Processing" tab and click "Add Filter" and select the "Workflow Processor".
* A modal popup presents the user to activate the filer and secondly the ability to search for the desired workflow in a search component. 
* Click save and close.
* Click submit on the "Filter Lists" form to save the changes.

=== Configuring Workflows
In order for a workflow to initiate a trigger from a API route a couple of steps need to be followed to complete the API to Workflow configuration

* Firstly navigate to the desired Worflow and click "Open Builder".
* On the desired Trigger enter the configuration option for the component
* Under the the configuration heading the default values are required
** Resource == System
** Event == onManual
* This allows a System generated trigger to receive the routes HTTP payload for consumption

=== Testing 
Testing the endpoint can be simply done by setting the route to a GET method and tested via a web browser or another API request builder such as POSTMAN.

// TODO 
// there should be a small animated gif showing the linking and testing of a route to its given workflow
// the workflow selector isnt in release so producing this now is redundant 


// workflow connections 





== Endpoint filters

Filters allow you to validate and process requests; as well as define the response.

[IMPORTANT]
====
Each endpoint can define at most one filter of the given type.
====

=== Prefilter

Prefilters allow you to validate the request to determine if the given endpoint should process it.
With prefilters, you can implement custom authentication and validation methods.

[NOTE]
====
It is currently not possible to use the built-in authentication facility to authenticate requests.
This will be added in the future.
====

.The list of available prefilters:
[cols="1s,5a"]
|===
| [#filters-prefilter-queryparam]#<<filters-prefilter-queryparam,Query parameters>>#
|
The query parameters prefilter allows you to define a condition which asserts if the request can be processed by this endpoint based on the query parameters.

The query parameters are passed into the expression evaluation engine as they were provided.
To examplify; the following query parameters `?param1=value1&param2=value2` would be referenced as `param1` and `param2` in the expression.

Refer to the xref:expr/index.adoc[expression] reference for details regarding writing these expressions.

The following example checks if the given HTTP request defines the `token` query param of `"super-secret-value"`.

.Endpoint definition:
* endpoint: `/test-query`
* method: `GET`
* query parameters prefilter expression: `token == "super-secret-value"`

.An example of an HTTP request that conforms to the filter:
[source,bash]
----
curl -X GET $BASE_URL/api/test-query?token=super-secret-value
----

.An example of an HTTP request that does not conform to the filter:
[source,bash]
----
curl -X GET $BASE_URL/api/test-query?token=some-other-value-i-guessed
----

[CAUTION]
====
Multi-word query parameters can currently not be used.
====

[CAUTION]
====
Multi-value query parameters can currently not be used.
====

| [#filters-prefilter-header]#<<filters-prefilter-header,Header>>#
|
The header prefilter allows you to define a condition which asserts if the request can be processed by this endpoint based on the request's headers.

All system defined headers are passed into the expression evaluation engine as provided.
User-define headers will automatically be converted into the `snake-case` + `PascalCase` format.
To examplify; `test-header` will become `Test-Header` and `test` becomes `Test`.

The following header `test: value` would be referenced as `Test` in the expression.

Refer to the xref:expr/index.adoc[expression] reference for details regarding writing these expressions.

The following example checks if the given HTTP request defines the `Token` header of `"super-secret-value"`.

.Endpoint definition:
* endpoint: `/test-query`
* method: `GET`
* header prefilter expression: `Token == "super-secret-value"`

.An example of an HTTP request that conforms to the filter:
[source,bash]
----
curl -X GET $BASE_URL/api/test-query \
  -H 'Token: super-secret-value'
----

.An example of an HTTP request that does not conform to the filter:
[source,bash]
----
curl -X GET $BASE_URL/api/test-query \
  -H 'Token: some-other-value-i-guessed'
----

[CAUTION]
====
Multi-word headers can currently not be used.
====

[CAUTION]
====
Multi-value headers can currently not be used.
====

|===

// #############################################################################


=== General Headers
Please refer to xref:https://www.tutorialspoint.com/http/http_header_fields.htm[tutorialspoint] for further examples and explanation.

.A list of available General Headers:
[cols="1m,5a"]
|===
| [#proc-js-input-Cache-Control]#<<proc-js-input-Cache-Control,Cache-Control>>#
|

*Request*
[source,bash]
----
Cache-control: [no-cache, no-store, max-age = seconds, max-stale = seconds, min-fresh, 	no-transform, only-if-cached]
----

*Response*
[source,bash]
----
Cache-control: [public, private, no-cache, no-store, no-transform, must-revalidate, proxy-revalidate, max-age = seconds, s-maxage = seconds]

----
| [#filters-prefilter-Connection]#<<filters-prefilter-Connection,Connection>>#
|

*Options*
[source,bash]
----
Connection: [close, keep-alive]
----


| [#filters-prefilter-Date]#<<filters-prefilter-Date,Date>>#
|


*Formats* 

* Sun, 06 Nov 1994 08:49:37 GMT ; RFC 822, updated by RFC 1123
* Sunday, 06-Nov-94 08:49:37 GMT ; RFC 850, obsoleted by RFC 1036
* Sun Nov 6 08:49:37 1994 ; ANSI C’s asctime() format


| [#filters-prefilter-Pragma]#<<filters-prefilter-Pragma,Pragma>>#
|


*Options*
[source,bash]
----
Pragma: [no-cache, no-cache]
----



| [#filters-prefilter-Trailer]#<<filters-prefilter-Trailer,Trailer>>#
|

*Options*
[source,bash]
----
Pragma: [no-cache, no-cache]
----


| [#filters-prefilter-Trailer]#<<filters-prefilter-Trailer,Trailer>>#
|


*Options*
[source,bash]
----
Pragma: [no-cache, no-cache]
----


Message header fields listed in the Trailer header field must not include the following header fields:

Transfer-Encoding

Content-Length




| [#filters-prefilter-Transfer-Encoding]#<<filters-prefilter-Transfer-Encoding,Transfer-Encoding>>#
|

Message header fields listed in the Trailer header field must not include the following header fields:

* Transfer-Encoding
* Content-Length
* Trailer
* Transfer-Encoding






| [#filters-prefilter-Upgrade]#<<filters-prefilter-Upgrade,Upgrade>>#
|


*Options*
[source,bash]
----
Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11
---- 



| [#filters-prefilter-Via]#<<filters-prefilter-Via,Via>>#
|


*Options*
[source,bash]
----
Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1)
----





| [#filters-prefilter-Warning]#<<filters-prefilter-Warning,Warning>>#
|

The Warning general-header is used to carry additional information about the status or transformation of a message which might not be reflected in the message

*Options*
[source,bash]
----
Warning : warn-code SP warn-agent SP warn-text SP warn-date
----

|===
// end table





=== Client Request Headers
.A list of available Client Request Headers:

.A list of available General Headers:
[cols="1m,5a"]
|===
| [#proc-js-input-Accept]#<<proc-js-input-Accept,Accept>>#
|

The Accept request-header field can be used to specify certain media types which are acceptable for the response

*Request*
[source,bash]
----
Accept: type/subtype [q=qvalue]
----


*Response*
[source,bash]
----
Accept: text/plain; q=0.5, text/html, text/x-dvi; q=0.8, text/x-c
----


| [#proc-js-input-Accept-Charset]#<<proc-js-input-Accept-Charset,Accept-Charset>>#
|


The Accept-Charset request-header field can be used to indicate what character sets are acceptable for the response

[source,bash]
----
Accept-Charset: character_set [q=qvalue]
Accept-Charset: iso-8859-5, unicode-1-1; q=0.8
Accept-Encoding: encoding types
Accept-Encoding
----

The Accept-Encoding request-header field is similar to Accept, but restricts the content-codings that are acceptable in the response.

[source,bash]
----
Accept-Encoding: encoding types
Accept-Encoding: compress, gzip
Accept-Encoding:
Accept-Encoding: *
Accept-Encoding: compress;q=0.5, gzip;q=1.0
Accept-Encoding: gzip;q=1.0, identity; q=0.5, *;q=0
---- 



| [#proc-js-input-Authorization]#<<proc-js-input-Authorization,Authorization>>#
|

The Authorization request-header field value consists of credentials containing the authentication information of the user agent for the realm of the resource being requested.

[source,bash]
----
Authorization : credentials

Authorization: BASIC Z3Vlc3Q6Z3Vlc3QxMjM=
----




| [#proc-js-input-Cookie]#<<proc-js-input-Cookie,Cookie>>#
|


The Cookie request-header field value contains a name/value pair of information stored for that URL

[source,bash]
----
Cookie: name=value
Cookie: name1=value1;name2=value2;name3=value3
----

|===






=== Server Response Headers

[cols="1m,5a"]
|===

| [#proc-js-input-Set-Cookie]#<<proc-js-input-Set-Cookie,Set-Cookie>>#
|
Set-Cookie

The Set-Cookie response-header field contains a name/value pair of information to retain for this URL.

*Request*
[source,bash]
----
Set-Cookie: name1=value1,name2=value2; Expires=Wed, 09 Jun 2021 10:18:14 GMT
----







| [#proc-js-input-Set-Cookie]#<<proc-js-input-Set-Cookie,Set-Cookie>>#
|

The Set-Cookie response-header field contains a name/value pair of information to retain for this URL.

*Request*
[source,bash]
----
Set-Cookie: name1=value1,name2=value2; Expires=Wed, 09 Jun 2021 10:18:14 GMT
----

*Response*
[source,bash]
----
Accept: text/plain; q=0.5, text/html, text/x-dvi; q=0.8, text/x-c
----


| [#proc-js-input-WWW-Authenticate]#<<proc-js-input-WWW-Authenticate,WWW-Authenticate>>#
|



The WWW-Authenticate response-header field must be included in 401 (Unauthorized) response messages. The field value consists of at least one challenge that indicates the authentication scheme(s) and parameters applicable to the Request-URI.

*Request*
[source,bash]
----
WWW-Authenticate : challenge
----


*Response*
[source,bash]
----
WWW-Authenticate: BASIC realm="Admin"
----






|===



=== Processing

A processor defines the core business logic that the endpoint performs.
{PRODUCT_NAME} allows you to process arbitrary payloads, such as a structured JSON or a binary attachment.

Most of the basic operations can be achieved with the built-in functionality; more advanced operations can be implemented with simple JavaScript code snippets or xref:automation/workflows/index.adoc[workflows].

.A list of available processors:
[cols="1s,5a"]
|===
| [#filters-proc-wfexec]#<<filters-proc-wfexec,Workflow processer>>#
|
The workflow processor allows you to bind a xref:automation/workflows/index.adoc[workflow] to the endpoint.

[NOTE]
====
*DevNote* better describe how workflows need to look like, the response, ...
====

| [#filters-proc-payloadproc]#<<filters-proc-payloadproc,Payload processer>>#
|
The payload processor allows you to handle the request's payload with the help of JavaScript.

Refer to the <<js-processing,JavaScript processing>> section for more details.

|===

=== Postfilter

Postfilters allow you to finalize the request lifecycle depending on the result of the processing.

.A list of available postfilters:
[cols="1s,5a"]
|===
| [#filters-postfilter-redirect]#<<filters-postfilter-redirect,Redirection>>#
|
The redirect postfilter enriches the response payload with the required redirect HTTP headers.

| [#filters-postfilter-json]#<<filters-postfilter-json,Default JSON response>>#
|
The JSON response postfilter enriches the response headers with the `application/json` content type and JSON encodes the processing results.

|===

// == Asynchronous endpoints

// Not in this version yet

// Asynchronous endpoints allow you to process long running operations without forcing the HTTP request to wait for the result.
// Asynchronous endpoints work exactly the same as synchronous (regular) ones, with the exception that the request is resolved right away.

// [NOTE]
// ====
// Asynchronous routes return the HTTP 202 response.
// Errors are logged in the logging system attached to {PRODUCT_NAME}.
// @todo factcheck
// ====

[#js-processing]
== JavaScript request processing

The API GW processing filter includes support to process the request using arbitrary JavaScript code.

[NOTE]
====
*DevNote* what restrictions does Goja implement?
====

The provided JavaScript code is automatically wrapped by a function with the signature of:

[source,ts]
----
function (input: Scope): unknown {
  // {{snippet}}
}
----

To examplify; the code snippet of `return "Hello, World!"` would become:

[source,js]
----
function (input) {
  return "Hello, World!"
}
----

The following example code snippet takes in the provided `name` and `surname` of our users and returns an array of `fullname` parameters.

[source,js]
----
// We firstly need to get the body of the request
var b = JSON.parse(readRequestBody(input.Get('request').Body));

return {
  // Assure correct casing
  "results":
    b.map(function({ name, surname }) {
        return {
          "fullname": name[0].toUpperCase() + name.substring(1) + " " + surname[0].toUpperCase() + surname.substring(1)
        }
    }),
  "count": b.length
};
----

The following cURL example invokes the above JavaScript function.

[source,bash]
----
curl -X GET $BASE_URL/api/test-js \
  -H "Content-Type: application/json" \
  -d "[{\"name\":\"johnny\", \"surname\":\"mnemonic\"},{\"name\":\"johnny\", \"surname\":\"knoxville\"}]";
----

=== Function arguments

The code snippet receives a single argument, `input`, that contains the entire request.

.The argument has the signature of:
[source,ts]
----
interface {
  Set: (k: string, v: unknown) => void;
  Get: (k: string) => unknown;
}
----

.The `input` object parameters:
[cols="1m,5a"]
|===
| [#proc-js-input-request]#<<proc-js-input-request,request>>#
|
The entire HTTP request object.
Refer to the https://pkg.go.dev/net/http?utm_source=gopls#Request[GO documentation] for detils regarding the signature.

| [#proc-js-input-opts]#<<proc-js-input-opts,opts>>#
|
API gateway configuration.
Refer to the https://github.com/cortezaproject/corteza-server/blob/2021.9.x/pkg/options/apigw.gen.go#L16[source] for details.

[NOTE]
====
*DevNote* generate above opt. docs
====

| [#proc-js-input-payload]#<<proc-js-input-payload,payload>>#
|
The string encoded request body content.
The content is extracted from `request.Body`

|===

=== Function result

The result of the JavaScript snippet is provided to the post filters that prepare and return an HTTP response.

When the result is a `string`, such as `Hello, World!`, the result is used as is.

When the result is a non-string value, such as `{ key: "value" }`, the result is JSON encoded.

=== Built-in function reference

[cols="1m,5m,5a,5a"]
|===
|Function |Signature |Description |Example

| [#proc-js-fnc-ref-readRequestBody]#<<proc-js-fnc-ref-readRequestBody,readRequestBody>>#
| readRequestBody
| readRequestBody(input: reader): string
| The function returns the contents of the provided request object.
| `readRequestBody(input.Get('request').Body)` returns the request's body as a string

[CAUTION]
====
The `readRequestBody` function may only be invoked once.
Additional invocations will return an empty response.

Use an intermediate variable if you need to read it multiple times.
====
|===

== Debugging

=== System logs

Enable debug logging in your `.env` file.
Refer to the xref:devops-guide:configuration/server.adoc[DevOps guide] for details.


=== Tail’ing docker logs

In order to view the live logs and the data being passed one needs to navigate to the root director of he docker files. Below is an example of naviagating to the location on a Ubuntu distro.

[source,bash]
----
cd /opt/deploy/{CORTEZA_INSTANCE}}/
----

Once navigated to above mentioned location you are able to tail the log file and filter for specific lines of output, as well as other Tail-f options.

[source,bash]
----
docker-compose logs -f --tail=20 server

server_1  | 12:53:14.862        DEBUG   rbac    rbac/service.go:102     allow delete for corteza::compose:record/245030892240891907/245030893465497603/246932114543603715       {"bypass": [], "context": [], "common": [245030892072923139], "authenticated": [245030891334791171], "anonymous": [], "identity": 250804535289769987, "indexed": 63, "rules": 420}
----


Tail a log for epecific "error" out puts.

[source,bash]
----
docker-compose logs -f --tail=20 server || grep
abadenhorst@mantle:/opt/deploy/herotel-sandbox.staging.crust.tech$ docker-compose logs -f --tail=20 server | grep DEBUG
server_1  | 13:52:29.636        DEBUG   rbac    rbac/service.go:102     allow triggers.manage for corteza::automation:workflow/248229091554160643
Last updated 2021-09-27 18:01:45 +0200
Some content has been disabled in this document
----